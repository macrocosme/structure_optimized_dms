{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Add modules paths to system path\n",
    "module_paths = ['.']\n",
    "for module_path in module_paths:\n",
    "    if os.path.abspath(os.path.join(module_path)) not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from psrpy.spectra import Spectra\n",
    "# from psrpy.rfifind import rfifind\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from time_domain_astronomy_sandbox.backend import Backend\n",
    "from time_domain_astronomy_sandbox.observation import Observation\n",
    "from time_domain_astronomy_sandbox.rfim import RFIm\n",
    "\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft, ifft\n",
    "import scipy.ndimage.filters as filters\n",
    "\n",
    "from blimpy import Waterfall\n",
    "from astropy.time import Time, TimeDelta\n",
    "\n",
    "current_input_id = -1\n",
    "\n",
    "\n",
    "input_filterbanks_repository = '../data/filterbanks/R3/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare bursts metadata\n",
    "(detection parameters, repository name, local and arts paths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fast_scandir(folder, ext, substrings=[]):\n",
    "    subfolders, files = [], []\n",
    "\n",
    "    for f in os.scandir(folder):\n",
    "        if f.is_dir():\n",
    "            subfolders.appaend(f.path)\n",
    "        if f.is_file():\n",
    "            if os.path.splitext(f.name)[1].lower() in ext:\n",
    "                if len(substrings) == 0:\n",
    "                    files.append(f.path)\n",
    "                else:\n",
    "                    found = True\n",
    "                    for s in substrings:\n",
    "                        if s not in os.path.splitext(f.name)[0]:\n",
    "                            found = False\n",
    "                    if found:\n",
    "                        files.append(f.path)\n",
    "\n",
    "    for folder in list(subfolders):\n",
    "        sf, f = run_fast_scandir(folder, ext, substrings)\n",
    "        subfolders.extend(sf)\n",
    "        files.extend(f)\n",
    "    return subfolders, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zapped_channels = np.array([189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 1534, 1535])\n",
    "detection_folders = ['2020-03-22-10:03:39.R3', '2020-03-23-11:05:38.R3', '2020-03-23-11:05:38.R3', '2020-03-23-11:05:38.R3', '2020-05-09-11:45:55.R3', '2020-05-10-09:41:43.R3', '2020-05-11-07:36:22.R3', '2020-05-11-07:36:22.R3', '2020-05-11-10:42:26.R3', '2020-05-11-10:42:26.R3', '2020-05-11-10:42:26.R3', '2020-05-11-10:42:26.R3', '2020-05-11-10:42:26.R3', '2020-05-11-10:42:26.R3', '2020-05-11-10:42:26.R3', '2020-05-11-14:40:00.R3', '2020-05-11-14:40:00.R3', '2020-05-11-14:40:00.R3', '2020-05-12-08:36:35.R3', '2020-05-27-03:20:38.R3', '2020-05-27-03:20:38.R3', '2020-05-27-03:20:38.R3', '2020-05-27-03:20:38.R3', '2020-05-27-07:21:12.R3', '2020-05-27-07:21:12.R3', '2020-05-27-10:52:06.R3', '2020-05-27-13:37:55.R3', '2020-05-27-13:37:55.R3', '2020-05-28-03:45:00.R3', '2020-05-28-05:13:48.R3', '2020-05-28-05:13:48.R3', '2020-05-28-08:19:28.R3', '2020-05-28-08:19:28.R3', ]\n",
    "observation_datetimes = ['%s%s%s' % (d[:10], 'T', d[11:].replace('.R3', '.0')) for d in detection_folders]\n",
    "detection_times = [4590.8, 4354.47, 7599.3, 9402.4, 9363.27, 9234, 3610.84, 6219.06, 4.15, 1780.7, 2317.14, 2688.72, 7153.32, 8913, 8959.9, 1495.37, 1889.1, 4387.14, 2216.21, 1612.21, 4810.98, 8867.2, 11658.7, 3592.32, 5082.87, 2616.07, 3437.12, 4390.28, 141.992, 2063.73, 4728.98, 1220.04, 3843.53, ]\n",
    "detection_mjd = Time(observation_datetimes, format='isot').mjd + TimeDelta(detection_times, format='sec')\n",
    "detection_dm = [348, 349, 348, 348, 348.2, 349, 348.2, 350.8, 352, 347.61, 349.2, 350.2, 354.45, 348, 350, 349.4, 348.06, 348.24, 350.3, 352.05, 349.49, 348.71, 349.2, 352.05, 354.2, 348.8, 351.8, 359.34, 348.4, 350.4, 349.56, 349.89, 349.09, ]\n",
    "detection_downsampling = [5.0, 5.0, 25.0, 5.0, 5.0, 10.0, 10.0, 25.0, 25.0, 100.0, 25.0, 10.0, 50.0, 1., 5.0, 10.0, 25.0, 10.0, 25.0, 50.0, 5.0, 5.0, 10.0, 50.0, 50.0, 5.0, 25.0, 250.0, 5.0, 25.0, 10.0, 5.0, 5.0]\n",
    "detection_snr = [11.5, 12.7, 13.4, 13.4, 13.6, 8.88, 16.38, 29.89, 13.86, 17.79, 10.12, 11.02, 38.61, 14, 12.5, 11.47, 58.14, 25.56, 31.5, 12.05, 12.67, 20.23, 20.95, 21.45, 19.48, 20.98, 20.87, 9.03, 25.71, 36.54, 29.9, 29.2, 20.92]\n",
    "detection_files, detection_filenames = [], []\n",
    "\n",
    "_, local_files = run_fast_scandir(input_filterbanks_repository, ['.fil'])\n",
    "arts_files = [\n",
    " '/tank/data/FRBs/R3/20200527/2020-05-27-10:52:06.R3/snippet/all/CB00_10.0sec_dm0_t02616_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200527/2020-05-27-03:20:38.R3/snippet/all/CB00_10.0sec_dm0_t01612_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200527/2020-05-27-03:20:38.R3/snippet/all/CB00_10.0sec_dm0_t011658_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200527/2020-05-27-03:20:38.R3/snippet/all/CB00_10.0sec_dm0_t04810_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200527/2020-05-27-03:20:38.R3/snippet/all/CB00_10.0sec_dm0_t08867_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200527/2020-05-27-13:37:55.R3/snippet/all/CB00_10.0sec_dm0_t03437_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200527/2020-05-27-13:37:55.R3/snippet/all/CB00_10.0sec_dm0_t04390_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200527/2020-05-27-07:21:12.R3/snippet/all/CB00_10.0sec_dm0_t05082_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200527/2020-05-27-07:21:12.R3/snippet/all/CB00_10.0sec_dm0_t03592_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200512/snippet/all/CB00_10.0sec_dm0_t02216_sb35_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200322/snippet/all/CB00_10.0sec_dm0_t04590_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200529/2020-05-29-03:20:12.R3/snippet/CB00_10.0sec_dm0_t01815_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t02317_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t03610_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t01495_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t01780_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t02688_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t06219_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t01889_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t08913_sb35_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t07153_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t04387_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t08959_sb35_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200511/snippet/all/CB00_10.0sec_dm0_t04_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200509/snippet/all/CB00_10.0sec_dm0_t09363_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200528/2020-05-28-03:45:00.R3/snippet/all/CB00_10.0sec_dm0_t0141_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200528/2020-05-28-08:19:28.R3/snippet/all/CB00_10.0sec_dm0_t03843_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200528/2020-05-28-08:19:28.R3/snippet/all/CB00_10.0sec_dm0_t01220_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200528/2020-05-28-05:13:48.R3/snippet/all/CB00_10.0sec_dm0_t04729_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200528/2020-05-28-05:13:48.R3/snippet/all/CB00_10.0sec_dm0_t02063_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200510/snippet/all/CB00_10.0sec_dm0_t09234_sb-1_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200323/snippet/CB00_10.0sec_dm0_t04354_sb35_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200323/snippet/CB00_10.0sec_dm0_t09402_sb35_tab00.fil',\n",
    " '/tank/data/FRBs/R3/20200323/snippet/CB00_10.0sec_dm0_t07599_sb35_tab00.fil']\n",
    "\n",
    "# Construct detection_files and detection_filenames \n",
    "for folder, t, snr in zip(detection_folders, detection_times, detection_snr):\n",
    "    date = \"\".join(folder.split('-')[:3])\n",
    "    found = False\n",
    "    for f in arts_files:\n",
    "        # If time and date somehwere in filename or in folder\n",
    "        if str(int(t)) in f and date in f:\n",
    "            for ff in local_files:\n",
    "                if f.split('/')[-1] == ff.split('/')[-1]:\n",
    "                    detection_files.append(ff)\n",
    "                    detection_filenames.append(ff.split('/')[-1].split('.fil')[0])\n",
    "                    \n",
    "                    found = True\n",
    "                    break\n",
    "        if found:\n",
    "            break\n",
    "    if not found:\n",
    "        detection_files.append('')\n",
    "        detection_filenames.append('')\n",
    "\n",
    "df_R3 = pd.DataFrame({'detection_folder': detection_folders, \n",
    "                      'observation_datetimes': observation_datetimes,\n",
    "                      'detection_time': detection_times, \n",
    "                      'detection_mjd': detection_mjd,\n",
    "                      'detection_dm': detection_dm, \n",
    "                      'detection_downsampling': detection_downsampling, \n",
    "                      'detection_snr': detection_snr, \n",
    "                      'filename': detection_filenames,\n",
    "                      'file_location': detection_files}).sort_values('detection_snr', ascending=True)\n",
    "\n",
    "# df_R3.to_csv('arts_R3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions \n",
    "## Needs some organizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_filterbank(filename:str,\n",
    "                    t_res:float = Backend().sampling_time, \n",
    "                    f_channels:list = Backend().frequencies[::-1],\n",
    "                    output_type:str='spectra'):\n",
    "\n",
    "    data = Waterfall(filename).data[:,0,:].T[::-1, :]\n",
    "    \n",
    "    if output_type == 'spectra':\n",
    "        return Spectra(f_channels,\n",
    "                       t_res,\n",
    "                       data)\n",
    "    elif output_type  == 'observation':\n",
    "        return Observation(backend=Backend(), \n",
    "                           length=data.data.shape[1]*data.dt,\n",
    "                           window=data.data)\n",
    "    \n",
    "def zoom_around_peak(spectra:Spectra, \n",
    "                     t_zoom:float = 1.):\n",
    "    peak_ind = np.argmax(spectra.data.sum(axis=0))\n",
    "    n_samp = int(np.round(t_zoom / spectra.dt))\n",
    "    samp_start = int(peak_ind - 0.5 * n_samp)\n",
    "    return data.data[:, samp_start:samp_start + n_samp]\n",
    "\n",
    "def get_dm_trials(estimated_dm:float = 349.2,\n",
    "                  dm_step:float = 0.1,\n",
    "                  dm_range:int = 5):\n",
    "    return np.arange(estimated_dm - dm_range, estimated_dm + dm_range + .5 * dm_step, dm_step)\n",
    "   \n",
    "def correct_bandpass(spectra:Spectra):\n",
    "    return spectra.data - np.mean(spectra.data, axis=1, keepdims=True)\n",
    "\n",
    "def downsample_freq(spectra:Spectra, \n",
    "                    factor:int = 2):\n",
    "    x, y = spectra.data.shape[0], spectra.data.shape[1]\n",
    "    x_fact, y_fact = factor, 1\n",
    "    return spectra.data.reshape(x//x_fact, x_fact, y, 1).mean(-1).mean(1)\n",
    "    \n",
    "def crop(spectra:Spectra, \n",
    "         t_zoom:float = 0.25,\n",
    "         around_peak=True):\n",
    "        \n",
    "    n_samp = int(np.round(t_zoom / spectra.dt))\n",
    "    if around_peak:\n",
    "        peak_ind = np.argmax(np.median(spectra.data, axis=0))\n",
    "        start = int(np.round(peak_ind - (0.5 * n_samp)))    \n",
    "    else:\n",
    "        start = int(np.round(spectra.data.shape[1]//2 - (0.5 * n_samp)))\n",
    "        \n",
    "    if start < 0:\n",
    "        n_samp += start\n",
    "        start = 0\n",
    "    \n",
    "    return spectra.data[:, start:start+n_samp]\n",
    "\n",
    "def to_snr(spectra:Spectra, axis=1):\n",
    "    data = spectra.data\n",
    "    data = data - np.nanmean(data, axis=axis)[:, None]\n",
    "    data = data / np.sqrt(np.nanvar(data, axis=axis))[:, None]\n",
    "    data[~np.isfinite(data)] = np.nanmedian(data)\n",
    "    return data\n",
    "\n",
    "def acf(x):\n",
    "    l = 2 ** int(np.log2(x.shape[1] * 2 - 1))\n",
    "    fftx = np.fft.fft(x, n = l, axis = 1)\n",
    "    ret = np.fft.ifft(fftx * np.conjugate(fftx), axis = 1)\n",
    "    ret = np.fft.fftshift(ret, axes=1)\n",
    "    return ret\n",
    "\n",
    "def subband(data, sub_factor, dim='freq'):\n",
    "    nfreq, nsamp = data.shape       \n",
    "    return np.nansum(\n",
    "        data.reshape(-1, sub_factor, nsamp) if dim == 'freq' else \\\n",
    "        data.reshape(nfreq, sub_factor, -1, order='f'), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "def get_yticks(freq_id_low, freq_id_high):\n",
    "    return np.linspace(freq_id_low  - 0.5, \n",
    "                       freq_id_high + 0.5, \n",
    "                       9)\n",
    "\n",
    "def get_yticklabels(f_channels, freq_id_low, freq_id_high):\n",
    "    df = np.median(np.diff(f_channels))\n",
    "    \n",
    "    return np.round(\n",
    "        np.linspace(\n",
    "            f_channels[freq_id_low - freq_id_low] - df / 2.,\n",
    "            f_channels[(freq_id_high - freq_id_low) - 1] + df / 2., \n",
    "            9\n",
    "        ), \n",
    "        1\n",
    "    )\n",
    "\n",
    "def dedisperse_waterfall(wfall, DM, freq, dt, ref_freq=\"top\"):\n",
    "    \"\"\"\n",
    "    D. Michilli's Dedisperse a wfall matrix to DM.\n",
    "    \"\"\"\n",
    "\n",
    "    k_DM = 1. / 2.41e-4\n",
    "    dedisp = np.zeros_like(wfall)\n",
    "\n",
    "    # pick reference frequency for dedispersion\n",
    "    if ref_freq == \"top\":\n",
    "        reference_frequency = freq[-1]\n",
    "    elif ref_freq == \"center\":\n",
    "        center_idx = len(freq) // 2\n",
    "        reference_frequency = freq[center_idx]\n",
    "    elif ref_freq == \"bottom\":\n",
    "        reference_frequency = freq[0]\n",
    "    else:\n",
    "        print(\"`ref_freq` not recognized, using 'top'\")\n",
    "        reference_frequency = freq[-1]\n",
    "\n",
    "    shift = (k_DM * DM * (reference_frequency**-2 - freq**-2) / dt).round().astype(int)\n",
    "    for i,ts in enumerate(wfall):\n",
    "        dedisp[i] = np.roll(ts, shift[i])\n",
    "    return dedisp\n",
    "\n",
    "def get_xticks(t0, t1):\n",
    "    return np.linspace(t0, \n",
    "                       t1, \n",
    "                       5)\n",
    "\n",
    "def get_xticklabels(t0, t1):    \n",
    "    return ['%.1f'  % (i) for i in np.linspace(\n",
    "            (-(t0 - (t1/2)) * spectra.dt) * 1000,\n",
    "            (-((t1/2) - t0) * spectra.dt) * 1000, \n",
    "            5\n",
    "        )]\n",
    "\n",
    "def get_cohenrent_spectrum(waterfall):\n",
    "    \"\"\"Get the coherent spectrum of the waterfall.\"\"\"\n",
    "\n",
    "    ft_waterfall = fft(waterfall)\n",
    "    amp = np.abs(ft_waterfall)\n",
    "    amp[amp == 0] = 1\n",
    "    spect = np.sum(ft_waterfall / amp, axis=0)\n",
    "    return spect\n",
    "\n",
    "def get_coherent_power(waterfall):\n",
    "    \"\"\"Get the coherent power of the waterfall.\"\"\"\n",
    "\n",
    "    spectra = get_cohenrent_spectrum(waterfall)\n",
    "    power = np.abs(spectra)**2\n",
    "    return power\n",
    "\n",
    "def prep_power(freq_id_low = 0,\n",
    "               freq_id_high = None,\n",
    "               t0 = 0,\n",
    "               t1 = None,\n",
    "               verbose=False):    \n",
    "    if verbose:\n",
    "        print ('Computing coherent power vs DM...')\n",
    "        print ()\n",
    "    waterfall, f_channels, freq_id_high, t1 = initialize_observation(freq_id_low=freq_id_low, \n",
    "                                                                     freq_id_high=freq_id_high, \n",
    "                                                                     t0=t0, \n",
    "                                                                     t1=t1)\n",
    "    \n",
    "    # Compute coherent power vs DM\n",
    "    nbin = int(np.round(waterfall.shape[1] / 2))\n",
    "    global power_vs_dm\n",
    "    power_vs_dm = np.zeros([nbin, dm_trials.size])\n",
    "    for i, dm in enumerate(dm_trials):\n",
    "        power_vs_dm[:, i] = get_coherent_power(\n",
    "            dedisperse_waterfall(waterfall,\n",
    "                                 dm,\n",
    "                                 f_channels,\n",
    "                                 spectra.dt)\n",
    "        )[:nbin]\n",
    "        \n",
    "    v = np.arange(0, nbin)\n",
    "    d_power_vs_dm = power_vs_dm * v[:, np.newaxis]**2\n",
    "    \n",
    "    return power_vs_dm, d_power_vs_dm\n",
    "\n",
    "def poly_max(x, y, Err):\n",
    "    \"\"\"\n",
    "    D. Michilli's Polynomial fit\n",
    "    \"\"\"\n",
    "    n = np.linalg.matrix_rank(np.vander(y))\n",
    "    p = np.polyfit(x, y, n)\n",
    "    Fac = np.std(y) / Err\n",
    "\n",
    "    dp      = np.polyder(p)\n",
    "    ddp     = np.polyder(dp)\n",
    "    cands   = np.roots(dp)\n",
    "    r_cands = np.polyval(ddp, cands)\n",
    "    first_cut = cands[(cands.imag==0) & \n",
    "                      (cands.real>=min(x)) & \n",
    "                      (cands.real<=max(x)) & \n",
    "                      (r_cands<0)]\n",
    "    \n",
    "    if first_cut.size > 0:\n",
    "        Value     = np.polyval(p, first_cut)\n",
    "        Best      = first_cut[Value.argmax()]\n",
    "        delta_x   = np.sqrt(np.abs(2 * Err / np.polyval(ddp, Best)))\n",
    "    else:\n",
    "        Best    = 0.\n",
    "        delta_x = 0.\n",
    "\n",
    "    return float(np.real(Best)), delta_x, p , Fac\n",
    "\n",
    "def plot_coherent_power(power_vs_dm, \n",
    "                        d_power_vs_dm, \n",
    "                        f_channels,\n",
    "                        nchan,\n",
    "                        estimated_dm,\n",
    "                        delta_dm, \n",
    "                        t0, \n",
    "                        t1, \n",
    "                        fluct_id_low, \n",
    "                        fluct_id_high,\n",
    "                        ax_power, \n",
    "                        ax_power_prof, \n",
    "                        ax_power_res,  \n",
    "                        cmap='viridis'):\n",
    "    \"\"\"Plot coherent power: fluctuation freq. vs DM\"\"\"\n",
    "\n",
    "    dm_curve = d_power_vs_dm[fluct_id_low : fluct_id_high].sum(axis=0)\n",
    "\n",
    "    fact_idx = fluct_id_low - fluct_id_high\n",
    "    _max   = dm_curve.max()\n",
    "    _nchan = len(f_channels)\n",
    "    _mean  = nchan              # Base on Gamma(2,)\n",
    "    _std   = _mean / np.sqrt(2)  # Base on Gamma(2,)\n",
    "    m_fact = np.sum(np.arange(fluct_id_low, fluct_id_high)**2)\n",
    "    s_fact = np.sum(np.arange(fluct_id_low, fluct_id_high)**4)**0.5\n",
    "    d_mean = _mean * m_fact\n",
    "    d_std  = _std  * s_fact\n",
    "    snr    = (_max - d_mean) / d_std\n",
    "\n",
    "    _peak  = dm_curve.argmax()\n",
    "    _range = np.arange(_peak - 5, _peak + 5)\n",
    "    y = dm_curve[_range]\n",
    "    x = dm_trials[_range]\n",
    "    returns_poly = poly_max(x, y, d_std)\n",
    "\n",
    "    # Profile\n",
    "    X, Y = dm_trials, dm_curve\n",
    "    ax_power_prof.plot(X, Y, linewidth=3, clip_on=False)\n",
    "    ax_power_prof.plot(X[_range], \n",
    "                       np.polyval(returns_poly[2], X[_range]), \n",
    "                       color='orange', \n",
    "                       linewidth=3, \n",
    "                       zorder=2, \n",
    "                       clip_on=False)\n",
    "    ax_power_prof.set_xlim([X.min(), X.max()])\n",
    "    ax_power_prof.set_ylim([Y.min(), Y.max()])\n",
    "    ax_power_prof.ticklabel_format(useOffset=False)\n",
    "    \n",
    "    ax_power_prof.text(0.1, 0.8, \n",
    "                       'S/N=%.2f' % (snr), \n",
    "                       horizontalalignment='center',\n",
    "                       verticalalignment='center', \n",
    "                       transform=ax_power_prof.transAxes)\n",
    "\n",
    "    # Residuals\n",
    "    res = y - np.polyval(returns_poly[2], x)\n",
    "    res -= res.min()\n",
    "    res /= res.max()\n",
    "    \n",
    "    ax_power_res.plot(x, res, 'x', linewidth=2, clip_on=False)\n",
    "    ax_power_res.set_ylim([np.min(res) - np.std(res) / 2, \n",
    "                           np.max(res) + np.std(res) / 2])\n",
    "    ax_power_res.set_ylabel('$\\Delta$')\n",
    "    ax_power_res.tick_params(axis='both', \n",
    "                             labelbottom='off', \n",
    "                             labelleft='off', \n",
    "                             direction='in', \n",
    "                             left='off', \n",
    "                             top='on')\n",
    "    ax_power_res.ticklabel_format(useOffset=False)\n",
    "\n",
    "    # Power vs DM map\n",
    "    FT_len = power_vs_dm.shape[0]\n",
    "    indx2Ang = 1. / (2 * FT_len * spectra.dt * 1000)\n",
    "    extent = [np.min(X), np.max(X), fluct_id_low * indx2Ang, fluct_id_high * indx2Ang]\n",
    "    \n",
    "    ax_power.imshow(power_vs_dm[fluct_id_low : fluct_id_high], \n",
    "                    origin='lower', \n",
    "                    aspect='auto', \n",
    "                    cmap=cmap, \n",
    "                    extent=extent, \n",
    "                    interpolation='nearest')\n",
    "    ax_power.tick_params(axis='both', \n",
    "                         direction='in', \n",
    "                         right='on', \n",
    "                         top='on')   \n",
    "   \n",
    "    dm = returns_poly[0]\n",
    "    dm_std = returns_poly[1]\n",
    "    \n",
    "    return dm, dm_std, snr\n",
    "    \n",
    "\n",
    "def plot_waterfall(waterfall, \n",
    "                   f_channels, \n",
    "                   t0, \n",
    "                   t1, \n",
    "                   freq_id_low, \n",
    "                   freq_id_high, \n",
    "                   ax_waterfall, \n",
    "                   ax_t_snr, \n",
    "                   ax_power_prof,\n",
    "                   ax_power_res,\n",
    "                   delta_dm, \n",
    "                   dm_std,\n",
    "                   cmap='viridis'\n",
    "                  ):\n",
    "    plot_wat_map = ax_waterfall.imshow(\n",
    "        waterfall, \n",
    "        origin='lower', \n",
    "        aspect='auto',\n",
    "        cmap=cmap, \n",
    "        interpolation='nearest',\n",
    "        extent=(t0 - 0.5, \n",
    "                t1 + 0.5, \n",
    "                freq_id_low  - 0.5, \n",
    "                freq_id_high + 0.5)\n",
    "    )\n",
    "    \n",
    "    # set time as label instead of channel numbers\n",
    "    ax_waterfall.set_xticks(\n",
    "        get_xticks(t0, t1)        \n",
    "    )\n",
    "    ax_waterfall.set_xticklabels(\n",
    "        get_xticklabels(t0, t1), \n",
    "#         rotation=90\n",
    "    )\n",
    "\n",
    "    # set frequencies as label instead of channel numbers\n",
    "    ax_waterfall.set_yticks(\n",
    "        get_yticks(freq_id_low, freq_id_high)\n",
    "    )\n",
    "    ax_waterfall.set_yticklabels(\n",
    "        get_yticklabels(f_channels, freq_id_low, freq_id_high), \n",
    "    )\n",
    "    \n",
    "    plot_wat_map.autoscale()\n",
    "\n",
    "    # plot summed profile\n",
    "    wat_prof = np.nansum(waterfall, axis=0)\n",
    "    plot_wat_prof, = ax_t_snr.plot(wat_prof, '-', linewidth=2)\n",
    "    ax_t_snr.set_ylim([wat_prof.min()-1, wat_prof.max()+1])\n",
    "    ax_t_snr.set_xlim([0, wat_prof.size])\n",
    "    ax_t_snr.text(0.1, 0.8, \n",
    "                  r'DM=%.2f $\\pm$ %.2f pc/cm$^3$' % (spectra.dm + delta_dm, dm_std), \n",
    "                  horizontalalignment='center',\n",
    "                  verticalalignment='center', \n",
    "                  transform=ax_t_snr.transAxes)\n",
    "\n",
    "    ax_power_prof.axis('off')\n",
    "    ax_power_res.axis('off')\n",
    "    ax_t_snr.axis('off')\n",
    "        \n",
    "    fig.canvas.draw()\n",
    "    display(fig)\n",
    "    \n",
    "def initialize_observation(freq_id_low = 0,\n",
    "                           freq_id_high = None,\n",
    "                           t0 = 0,\n",
    "                           t1 = None):\n",
    "    \n",
    "    if freq_id_high is None:\n",
    "        freq_id_high = spectra.data.shape[0]\n",
    "\n",
    "    if t1 is None:\n",
    "        t1 = spectra.data.shape[1]\n",
    "    \n",
    "    waterfall = spectra.data[int(freq_id_low):int(freq_id_high), int(t0):int(t1)]\n",
    "    f_channels = spectra.freqs[int(freq_id_low):int(freq_id_high), ...]\n",
    "        \n",
    "    return waterfall, f_channels, freq_id_high, t1\n",
    "\n",
    "def set_layout():    \n",
    "    # Fluctuation vs dDM\n",
    "    ax_power_prof = fig.add_subplot(gs[0:4, 0:3])\n",
    "    ax_power_prof.clear()\n",
    "    \n",
    "    ax_power_res = fig.add_subplot(gs[4:5, 0:3])\n",
    "    ax_power_res.clear()\n",
    "    \n",
    "    ax_power = fig.add_subplot(gs[5:, 0:3])\n",
    "    ax_power.clear()\n",
    "    ax_power.set_xlabel(r'$\\Delta$DM (pc/cc)')\n",
    "    ax_power.set_ylabel(r'Fluctuation frequency (ms$^{-1}$)')\n",
    "    \n",
    "    \n",
    "    # Waterfall\n",
    "    ax_t_snr = fig.add_subplot(gs[0:4, 3:])\n",
    "    ax_t_snr.clear()\n",
    "\n",
    "    ax_waterfall = fig.add_subplot(gs[5:, 3:])\n",
    "    ax_waterfall.clear()\n",
    "    ax_waterfall.set_xlabel('Time (ms)')\n",
    "    ax_waterfall.set_ylabel('Frequency (MHz)')\n",
    "    \n",
    "#     # ACF\n",
    "#     ax_acf_prof = fig.add_subplot(gs[0:4, 6:])\n",
    "#     ax_acf_prof.clear()\n",
    "\n",
    "#     ax_acf = fig.add_subplot(gs[5:, 6:])\n",
    "#     ax_acf.clear()\n",
    "#     ax_acf.set_xlabel('Time (ms)')\n",
    "#     ax_acf.set_ylabel('Frequency (MHz)')\n",
    "    \n",
    "    return ax_t_snr, ax_waterfall, ax_power_prof, ax_power, ax_power_res\n",
    "\n",
    "def select_frequency_range(fluct_id_low = 0,\n",
    "                           fluct_id_high = 30,\n",
    "                           freq_id_low = 0,\n",
    "                           freq_id_high = None,\n",
    "                           t0 = 0,\n",
    "                           t1 = None,\n",
    "                           ds_freq = 1,\n",
    "                           ds_time = 1,\n",
    "                           delta_dm = 0,\n",
    "                           smooth = 0):\n",
    "    \"\"\"Select a frequency range from the waterfall 2D array.\"\"\"   \n",
    "    \n",
    "    # Prep figure layout\n",
    "    ax_t_snr, ax_waterfall, ax_power_prof, ax_power, ax_power_res = set_layout()\n",
    "    \n",
    "    # Initialize observation data\n",
    "    waterfall, f_channels, freq_id_high, t1 = initialize_observation(freq_id_low=freq_id_low, \n",
    "                                                                     freq_id_high=freq_id_high, \n",
    "                                                                     t0=t0, \n",
    "                                                                     t1=t1)              \n",
    "    \n",
    "    dm, dm_std, snr = plot_coherent_power(filters.gaussian_filter(power_vs_dm, smooth), \n",
    "                                          filters.gaussian_filter(d_power_vs_dm, smooth), \n",
    "                                          f_channels,\n",
    "                                          waterfall.shape[0],\n",
    "                                          spectra.dm,\n",
    "                                          delta_dm, \n",
    "                                          t0, \n",
    "                                          t1, \n",
    "                                          fluct_id_low, \n",
    "                                          fluct_id_high,\n",
    "                                          ax_power, \n",
    "                                          ax_power_prof, \n",
    "                                          ax_power_res)\n",
    "    \n",
    "    ax_power.vlines(dm + delta_dm, \n",
    "                    ax_power.get_ylim()[0],\n",
    "                    ax_power.get_ylim()[1], \n",
    "                    alpha=0.7, \n",
    "                    color='red')\n",
    "\n",
    "    global struct_opt_dm, struct_opt_dm_err\n",
    "    struct_opt_dm, struct_opt_dm_err = delta_dm + dm, dm_std\n",
    "    \n",
    "    waterfall = dedisperse_waterfall(waterfall,\n",
    "                                     delta_dm + dm,\n",
    "                                     f_channels,\n",
    "                                     spectra.dt)\n",
    "    \n",
    "    global sub_waterfall \n",
    "    sub_waterfall = subband(\n",
    "        subband(\n",
    "            waterfall, \n",
    "            ds_freq, \n",
    "            dim='freq'\n",
    "        ), \n",
    "        ds_time, \n",
    "        dim='time'\n",
    "    )\n",
    "    \n",
    "    plot_waterfall(sub_waterfall, \n",
    "                   f_channels, \n",
    "                   t0, \n",
    "                   t1, \n",
    "                   freq_id_low, \n",
    "                   freq_id_high, \n",
    "                   ax_waterfall, \n",
    "                   ax_t_snr, \n",
    "                   ax_power_prof, \n",
    "                   ax_power_res,\n",
    "                   delta_dm + dm, \n",
    "                   dm_std)\n",
    "    \n",
    "def prep_data(file, estimated_dm, downsampling, around_peak=True, verbose=False):\n",
    "    \"\"\"Prepare data for analysis and plotting\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print ('Preprocessing data...')\n",
    "        print ()\n",
    "    \n",
    "    t_res = Backend().sampling_time\n",
    "    f_channels = Backend().frequencies\n",
    "    dm_trials = get_dm_trials(estimated_dm = 0,\n",
    "                          dm_step = 0.1,\n",
    "                          dm_range = 10)\n",
    "\n",
    "    spectra = read_filterbank(file,\n",
    "                              t_res = t_res,\n",
    "                              f_channels = f_channels)\n",
    "\n",
    "    spectra.data = RFIm().dm0clean(spectra.data)\n",
    "    spectra.dedisperse(dm=estimated_dm)\n",
    "#     spectra.downsample(factor=downsampling)\n",
    "#     spectra.subband(spectra.data.shape[0]//4)\n",
    "    spectra.data = correct_bandpass(spectra.data)\n",
    "    spectra.data = RFIm().tdsc_amber(spectra.data)\n",
    "#     spectra.data = RFIm().fdsc_amber(spectra.data)\n",
    "        \n",
    "    spectra.data = crop(spectra, \n",
    "                        t_zoom=0.05 if downsampling < 25 else 0.1 if downsampling > 1 else 0.015,\n",
    "                        around_peak = around_peak)\n",
    "    \n",
    "    spectra.data = to_snr(spectra.data)\n",
    "    \n",
    "    return spectra, dm_trials\n",
    "    \n",
    "def initialize(input_filename, estimated_dm, downsampling, verbose=False):\n",
    "    if verbose:\n",
    "        print ('Loading data... %s' % (input_filename))\n",
    "        print ()\n",
    "    spectra, dm_trials = None, None\n",
    "    i = 0\n",
    "    filename = ''\n",
    "\n",
    "    try:\n",
    "        plt.clf()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        spectra, dm_trials = prep_data(input_filename, \n",
    "                                       estimated_dm, \n",
    "                                       downsampling, \n",
    "                                       around_peak=True, \n",
    "                                       verbose=verbose)\n",
    "    except IndexError:\n",
    "        print ('Errror with %s' % file)\n",
    "        print ()\n",
    "        spectra, dm_trials = prep_data(input_filename, \n",
    "                                       estimated_dm, \n",
    "                                       downsampling, \n",
    "                                       around_peak=False, \n",
    "                                       verbose=verbose)\n",
    "        \n",
    "    return spectra, dm_trials, input_filename\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "verbose = True\n",
    "\n",
    "# Go from one file to the other in the list in ascending (True) or decending (False) order\n",
    "# `None` will reload the same file.\n",
    "incr = False\n",
    "\n",
    "if incr:\n",
    "    current_input_id += 1\n",
    "elif incr is not None:\n",
    "    current_input_id -= 1\n",
    "\n",
    "print ('Current burst:')\n",
    "print (df_R3.iloc[current_input_id])\n",
    "print ()\n",
    "\n",
    "if df_R3.iloc[current_input_id]['file_location'] == '':\n",
    "    if incr:\n",
    "        current_input_id += 1\n",
    "    elif incr is not None:\n",
    "        current_input_id -= 1\n",
    "    \n",
    "# Global variables for interaction in next panel\n",
    "spectra, dm_trials, filename = initialize(df_R3.iloc[current_input_id]['file_location'], \n",
    "                                          df_R3.iloc[current_input_id]['detection_dm'],\n",
    "                                          df_R3.iloc[current_input_id]['detection_downsampling'],\n",
    "                                          verbose=verbose)\n",
    "detection_mjd = df_R3.iloc[current_input_id]['detection_mjd']\n",
    "power_vs_dm, d_power_vs_dm = prep_power(verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(10, 7))\n",
    "gs = fig.add_gridspec(15, 6)\n",
    "\n",
    "interact(\n",
    "    select_frequency_range, \n",
    "    fluct_id_low = widgets.IntSlider(min = 0, \n",
    "                                     max = power_vs_dm.shape[0], \n",
    "                                     step = 1, \n",
    "                                     value = 0, \n",
    "                                     continuous_update=False), \n",
    "    fluct_id_high = widgets.IntSlider(min = 0, \n",
    "                                      max = power_vs_dm.shape[0], \n",
    "                                      step = 1, \n",
    "                                      value = power_vs_dm.shape[0], \n",
    "                                      continuous_update=False), \n",
    "    freq_id_low = widgets.IntSlider(min = 0, \n",
    "                                    max = spectra.data.shape[0], \n",
    "                                    step = 1, \n",
    "                                    value = 0, \n",
    "                                    continuous_update=False),\n",
    "    freq_id_high = widgets.IntSlider(min = 1, \n",
    "                                     max = spectra.data.shape[0], \n",
    "                                     step = 1, \n",
    "                                     value = spectra.data.shape[0], \n",
    "                                     continuous_update=False),\n",
    "    t0 = widgets.IntSlider(min = 0, \n",
    "                           max = spectra.data.shape[1], \n",
    "                           step = 1, \n",
    "                           value = 0, \n",
    "                           continuous_update=False), \n",
    "    t1 = widgets.IntSlider(min = 1, \n",
    "                           max = spectra.data.shape[1], \n",
    "                           step = 1, \n",
    "                           value = spectra.data.shape[1], \n",
    "                           continuous_update=False),\n",
    "    ds_freq = widgets.IntSlider(min=1, \n",
    "                                max=32, \n",
    "                                step=1, \n",
    "                                value=1, \n",
    "                                continuous_update=False),\n",
    "    ds_time = widgets.IntSlider(min=1, \n",
    "                                max=32, \n",
    "                                step=1, \n",
    "                                value=1, \n",
    "                                continuous_update=False),\n",
    "    delta_dm = widgets.FloatSlider(min = -10, \n",
    "                                   max = 10, \n",
    "                                   step = 0.01, \n",
    "                                   value = 0, \n",
    "                                   continuous_update=False),\n",
    "    smooth = widgets.IntSlider(min=0, \n",
    "                               max=4, \n",
    "                               step=1, \n",
    "                               value=0, \n",
    "                               continuous_update=False),\n",
    "    \n",
    ")\n",
    "\n",
    "# Save button\n",
    "button = widgets.Button(description=\"Save figure\")\n",
    "display(button)\n",
    "\n",
    "button_raw = widgets.Button(description=\"Save raw figure\")\n",
    "display(button_raw)\n",
    "\n",
    "def save_dm_to_df():\n",
    "    df_R3.loc[df_R3['detection_mjd'] == detection_mjd, 'struct_opt_dm'] = struct_opt_dm \n",
    "    df_R3.loc[df_R3['detection_mjd'] == detection_mjd, 'struct_opt_dm_err'] = struct_opt_dm_err\n",
    "    \n",
    "    df_R3.to_csv('arts_r3.csv', index=False)\n",
    "\n",
    "def check_dir(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "def save_figure(b):\n",
    "    check_dir('images/manual_opt')\n",
    "    check_dir('images/manual_opt/data')\n",
    "    \n",
    "    print (\"saved to images/manual_opt/%s.png\" % (filename.split('/')[-1].split('.fil')[0]))\n",
    "    fig.savefig(\"images/manual_opt/%s.png\" % (filename.split('/')[-1].split('.fil')[0]), dpi=300)\n",
    "\n",
    "    with open(\"images/manual_opt/data/%s_waterfall.npy\" % (filename.split('/')[-1].split('.fil')[0]), 'wb') as f:\n",
    "        np.savetxt(f, sub_waterfall)\n",
    "    with open(\"images/manual_opt/data/%s_fluctuation.npy\" % (filename.split('/')[-1].split('.fil')[0]), 'wb') as f:\n",
    "        np.savetxt(f, power_vs_dm)\n",
    "        \n",
    "    save_dm_to_df()\n",
    "        \n",
    "def save_figure_raw(b):\n",
    "    check_dir('images/manual_opt/raw')\n",
    "    check_dir('images/manual_opt/raw/data')\n",
    "    \n",
    "    \n",
    "    print (\"saved to images/manual_opt/raw/%s.png\" % (filename.split('/')[-1].split('.fil')[0]))\n",
    "    fig.savefig(\"images/manual_opt/raw/%s.png\" % (filename.split('/')[-1].split('.fil')[0]), dpi=300)\n",
    "\n",
    "    with open(\"images/manual_opt/raw/data/%s_waterfall.npy\" % (filename.split('/')[-1].split('.fil')[0]), 'wb') as f:\n",
    "        np.savetxt(f, sub_waterfall)\n",
    "    with open(\"images/manual_opt/raw/data/%s_fluctuation.npy\" % (filename.split('/')[-1].split('.fil')[0]), 'wb') as f:\n",
    "        np.savetxt(f, power_vs_dm)\n",
    "        \n",
    "    save_dm_to_df()\n",
    "\n",
    "button.on_click(save_figure)\n",
    "button_raw.on_click(save_figure_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev zone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra.data.reshape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "\n",
    "np.nansum(\n",
    "    arr.reshape(2, 2, -1, order='f'),\n",
    "    axis = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
